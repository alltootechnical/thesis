\section{Methodology}
\label{sec:chapter_3}
\subsection{System Implementation}
A wrapper library was created in Python 3.7.1 that combines the Paillier, DGK, and BGV cryptosystems into a unified interface.
\begin{itemize}
	\item The Paillier cryptosystem is incorporated using the python-paillier library at \url{https://github.com/n1analytics/python-paillier} developed by Data61 - CSIRO.
	\item The DGK cryptosystem is ported from the C++ implementation at \url{https://github.com/encryptogroup/ENCRYPTO_utils}, developed by Daniel Demmler from EC-SPRIDE.
	\item The BGV cryptosystem is implemented using the Pyfhel library (\url{https://github.com/ibarrond/Pyfhel}) using a HElib backend from (\url{https://github.com/shaih/HElib}).
\end{itemize}

\subsection{Assessment of Homomorphic Encryption Schemes}
\subsubsection{Image Quality of Intensity Transformations}
We obtained ten test images from the \texttt{faces94} dataset (\url{https://cswww.essex.ac.uk/mv/allfaces/faces94.html}) maintained by the University of Essex. The images were converted to grayscale and then downsampled to $40 \times 36$ pixels.
For each cryptosystem, three image operations are tested, as they are defined in Table \ref{tab:imageoperation_summary}:
\begin{enumerate}
	\item Image negation
	\item Logarithm transformation, with $c = 30$
	\item Power-law transformation, with $c = 1$ and $\gamma = 0.4$
\end{enumerate}
The logarithm transformation was implemented using the approximation in Equation \ref{eq:optimal_log_approximation}, while the exponentiation in the power-law transformation was implemented by evaluating the sum of the first five terms of the infinite series in Equation \ref{eq:power_approximation}.

A laptop computer with a 2.5 GHz Intel Core i7 quad-core processor and 8 GB of RAM is used to perform the computations, and processing time was tracked using built-in timing functions. The processing time for all cases were recorded. All of the tests are done using Python 3.7.1 running on Linux.

For each plaintext image (PT), we considered each image operation listed above and generate three images: a plaintext domain transformation (PDT), a ciphertext image (CT), and an ciphertext domain transformation (CDT). The PDT was generated by running the image operation on the original image. The CT was generated by encrypting the image, then applying the operation, and the CDT was generated by decrypting the CT. The PT, PDT, and CDT were then compared using image quality benchmarks to evaluate the applicability of each homomorphic encryption scheme.

We perform three tests to ascertain the preservation of image quality after encryption and decryption: mean squared error (MSE), peak signal to noise ratio (PSNR), and structural similarity index (SSIM), adopted from~\cite{ahmed_benchmark_2016, ahmad_efficiency_2012, wu_npcr_2011}. These statistics were computed using the corresponding built-in functions from the scikit-image Python library \cite{scikit-image}.
\begin{description}
	\item [Mean Squared Error (MSE).]
	By computing mean squared error between the PDT and the CDT, we obtain a measure of how much image quality is retained after encryption, transformation, and decryption. Lower values of MSE indicate higher preservation of image quality~\cite{ahmed_benchmark_2016, ahmad_efficiency_2012}.
	\item [Peak Signal to Noise Ratio (PSNR).]
	We compute the PSNR from the MSE. The PSNR is ``an estimator for human visual perception of reconstruction quality.''~\cite{ahmed_benchmark_2016}. Although it may produce results which do not correlate with human visual perception~\cite{huynh-thu_accuracy_2012, ahmed_benchmark_2016}, it is a valid indicator of image quality when media containing the same visual content is compared~\cite{huynh-thu_accuracy_2012}, and is a known metric for image and video quality~\cite{upmanyu_efficient_2009, jain_image_2016, akramullah_video_2014}. A higher PSNR indicates higher image quality preservation.
	\item [Structural Similarity Index (SSIM).]
	We compute the SSIM between the PDT and the CDT. The SSIM is applied to the luminance value of two images to gauge structural similarity between neighboring pixels. Higher values of SSIM indicate higher structural similarity, and an SSIM of $1$ indicates that the two images are identical~\cite{ahmed_benchmark_2016}.
\end{description}
\subsubsection{Facial Recognition Tests}
The method for secure facial recognition using eigenfaces by Erkin, et al. \cite{hutchison_privacy-preserving_2009} was implemented for this study.

As before, training and test data were also secured from the \texttt{faces94} dataset. The images were first converted to grayscale and then downsampled to $40 \times 36$ pixels.

The facial recognition tests are done using ten-fold cross-validation for each cryptosystem, where the number of principal components used by the algorithm is fixed at $K=5$.

Prior to splitting the dataset, the images within each set are shuffled. Since there are twenty (20) images per set, two images are taken at a time for each round of cross-validation. The first round would take the first two images from each set as part of the test set, and the rest of the images will be part of the training set. Then, the succeeding round would take the next two images from each set as part of the test set, and so on until ten rounds have been done. After every round of cross-validation, the accuracy score, confusion matrix, and total processing time are obtained.

%% Summary not needed, this was only important for the thesis proposal - Aldrich
% \subsection{Summary}
% In summary, the study consists of:
% \begin{itemize}
% 	\item Creating a wrapper library that acts as a unified interface which implements the Paillier, DGK, Dasgupta--Pal, and BGV homomorphic cryptosystems.
% 	\item An implementation of image processing operations (intensity transformations, facial recognition) under the above cryptosystems.
% 	\item Conducting tests for image quality, processing time, using images from the \texttt{faces94} dataset.
% \end{itemize}
