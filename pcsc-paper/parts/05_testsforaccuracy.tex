\section{Experiments on Accuracy}
We implemented privacy-preserving floating-point arithmetic using the system described in Section~\ref{sec:fp_arithmetic}, through the \texttt{python-paillier} library (\url{https://github.com/n1analytics/python-paillier}) running on Python~3.6.5.

\subsection{Logarithm Approximation}
We then computed $\log\left(1+x\right)$ for various encrypted inputs using both the original quadrature formula by Khattri (Equation~\ref{eq:standard_logarithm_quadrature}) and our scaled approximation (Equation~\ref{eq:optimal_log_approximation}). These were compared with the values returned by the built-in logarithm function in Python. Several data points are shown in Table~\ref{tab:log_approximation}.

We note that the privacy-preserving floating-point arithmetic resulted in some degree of floating-point error, as the observed floating point error in Table~\ref{tab:log_approximation} is greater than the raw absolute error observed in Figure~\ref{fig:log_error_comparison}. However, it can still be seen that the error of the scaled approximation is less than that of the original approximation for large inputs, although this approximation loses accuracy for smaller inputs.
\begin{table}[ht]
	\caption{Comparison of logarithm approximation errors under Paillier}
	\label{tab:log_approximation}
	\begin{tabular}{lcc}
		\toprule
		Input & Original quadrature & Scaled quadrature\\
		\midrule
		$\log 1$ & $0$ & $2.053729 \times 10^{-2}$\\
		$\log 10$ & $2.833179 \times 10^{-2} $ & $2.280124 \times 10^{-1}$\\
		$\log 50$ & $2.170779 \times 10^{-2}$ & $2.437148 \times 10^{-2}$\\
		$\log 100$ & $3.524916 \times 10^{-1}$ & $2.122159 \times 10^{-2}$\\
		$\log 200$ & $8.859869 \times 10^{-1}$ & $1.441611 \times 10^{-1}$\\
		$\log 256$ & $1.098463 \times 10^{0}$ & $1.993136 \times 10^{-1}$\\
	\bottomrule
\end{tabular}
\end{table}

\begin{figure}[!ht]
	\centering
	\begin{tikzpicture}
		\begin{semilogyaxis}[
			xmin=0, xmax=255,
			ymin=1e-3, ymax=1.5,
			xlabel={$x$}, ylabel={Absolute error},
			grid=major,
			legend pos=south east,
			legend cell align=left,
			tick scale binop=\times,
		]
		\addplot[very thick, ACMDarkBlue] table[x=x, y=newerr] {plots/comp_log_errs.txt};
		\addplot[thick, ACMOrange] table[x=x, y=olderr] {plots/comp_log_errs.txt};
		\legend{Scaled quadrature, Original quadrature}
		\end{semilogyaxis}
	\end{tikzpicture}%
	\caption{Comparison of logarithm approximation errors under Paillier}
	\label{fig:comp_log}
\end{figure}

\subsection{Inverse Tangent Approximation}
We also computed $\arctan x$ using for various encrypted inputs using both the first five terms of Euler's series for the inverse tangent function (Equation~\ref{eq:arctan_euler_partial}) and our quadrature approximation (Equation~\ref{eq:arctan_quadrature}). These were compared with the values returned by the built-in inverse tangent function in Python. We show several data points in Table~\ref{tab:arctan_approximation}. Similar to the logarithm approximations, we note that there is a degree of floating-point error compared to that predicted by Figure~\ref{fig:arctan_error}, but the quadrature approach obtains higher accuracy despite requiring a similar number of floating-point operations to execute.

\begin{table}[ht]
	\caption{Comparison of inverse tangent approximation errors under Paillier}
	\label{tab:arctan_approximation}
	\begin{tabular}{lcc}
		\toprule
		Input & Partial sum of infinite series & Quadrature\\
		\midrule
		$\arctan -1$ & $6.564089 \times 10^{-1}$ & $4.629557 \times 10^{-1}$\\
		$\arctan -0.1$ & $4.523405 \times 10^{-3}$ & $1.451929 \times 10^{-3}$\\
		$\arctan -0.01$ & $4.665260 \times 10^{-6}$ & $1.472027 \times 10^{-6}$\\
		$\arctan 0$ & $0$ & $0$\\
		$\arctan 0.01$ & $4.665228 \times 10^{-6}$ & $1.472020 \times 10^{-6}$\\
		$\arctan 0.1$ & $4.523405 \times 10^{-3} $ & $1.451929 \times 10^{-3}$\\
		$\arctan 1$ & $6.564089 \times 10^{-1} $ & $4.629557 \times 10^{-1}$\\
	\bottomrule
\end{tabular}
\end{table}

\begin{figure}[!ht]
	\centering
	\begin{tikzpicture}
		\begin{semilogyaxis}[
			xmin=-1, xmax=1,
			ymin=1e-7, ymax=1,
			xlabel={$x$}, ylabel={Absolute error},
			grid=major,
			legend pos=south east,
			legend cell align=left,
			tick scale binop=\times,
		]
		\addplot[very thick, ACMDarkBlue] table[x=x, y=newerr] {plots/comp_arctan_errs.txt};
		\addplot[thick, ACMOrange] table[x=x, y=olderr] {plots/comp_arctan_errs.txt};
		\legend{Gauss--Legendre quadrature, Partial sum of Euler's series}
		\end{semilogyaxis}
	\end{tikzpicture}%
	\caption{Comparison of inverse tangent approximation errors under Paillier}
	\label{fig:comp_arctan}
\end{figure}

