\chapter{METHODOLOGY}

In this study we apply four homomorphic encryption schemes~\cite{ziad_cryptoimg:_2016, pieprzyk_efficient_2007, dasgupta_design_2016, garay_algorithms_2014} for use in image processing and facial recognition applications.
While the Paillier and DGK cryptosystems have been implemented for use in image processing in~\cite{ziad_cryptoimg:_2016, hutchison_privacy-preserving_2009}, the other cryptosystems have to be adapted for this study.
Two experiments were conducted in this study:
\begin{enumerate}
	\item Assessment of non-linear image intensity transformations under each of the four cryptosystems.
	\item Assessment of efficiency of each of the four cryptosystems when applied for use in privacy-preserving facial recognition and detection using eigenfaces.
\end{enumerate}
The results of the image intensity transformations were tested for image quality using benchmarks in~\cite{ahmed_benchmark_2016}.

\section{Cryptosystem Implementation}

% The current version of the OpenCV library (3.4.2) will be forked from the open-source GitHub repository at \url{https://github.com/opencv/opencv})~\cite{bradski_opencv_2000}.

Four homomorphic encryption schemes were investigated. For cryptosystems with readily available open-source implementations, such implementations were used. For the remaining cryptosystems, the encryption and decryption methods were implemented in Python.
\begin{itemize}
	\item The Paillier cryptosystem was incorporated using the implementation at \url{https://github.com/n1analytics/python-paillier} developed by Data61 - CSIRO.
	\item The BGV cryptosystem was implemented using the Pyfhel library (\url{https://github.com/ibarrond/Pyfhel}) using a HElib backend from (\url{https://github.com/shaih/HElib}).
	\item The DGK and Dasgupta--Pal cryptosystem were implemented from scratch.
\end{itemize}

For convenience, a wrapper library was created that integrates the four cryptosystems into a unified interface.

\input{parts/03_methodology_01integertorealnumbers}
\input{parts/03_methodology_02nonlinearintensitytransformations}

\section{Assessment of Homomorphic Encryption Schemes}

Lab computers in Faura Hall, Ateneo de Manila University were used to perform the computations, and processing time was tracked using built-in timing functions. The processing time for all cases were recorded.

\subsection{Image Quality of Intensity Transformations}
In this section, we discuss the image quality metrics we used for assessing the performance of non-linear intensity transformations.

We first obtained standard test images from~\cite{gonzalez_image_nodate}. Grayscale images were used in the study.

For each plaintext image (PT), we considered each image operation listed above and generate three images: a plaintext domain transformation (PDT), a ciphertext image (CT), and an encrypted domain transformation (EDT). The PDT was generated by running the image operation on the original image. The CT was generated by encrypting the image, then applying the operation, and the EDT was generated by decrypting the CT. The four images (PT, PDT, CT, EDT) were then compared using various benchmarks to evaluate the quality and security of each homomorphic encryption scheme.

The benchmarks to be used in the study, adopted from~\cite{ahmed_benchmark_2016, ahmad_efficiency_2012, wu_npcr_2011} are listed below. We let $X_i$ denote a value in an image $X$, where $1 \leq i \leq N$.
We first perform three tests to ascertain the preservation of image quality after encryption and decryption: MSE, PSNR, and SSIM.
\begin{description}
	\item [Mean Squared Error (MSE).] The MSE is defined in~\cite{ahmed_benchmark_2016} as
	\begin{align}
        \mathrm{MSE} = \frac{1}{N}\sum_{i=1}^{N}{(\mathrm{CDT}_i - \mathrm{PDT}_i)^2}.
	\end{align}
	The MSE provides a measure of how much data is recovered if an image operation is applied on the encrypted image, which is then decrypted. Lower values of MSE indicate higher preservation of image quality~\cite{ahmed_benchmark_2016, ahmad_efficiency_2012}.
	\item [Peak Signal to Noise Ratio (PSNR).]
	According to Ahmed, et al.~\cite{ahmed_benchmark_2016}, PSNR is ``an estimator for human visual perception of reconstruction quality.'' It has been used to ascertain image quality in various studies and is a known metric for image and video quality~\cite{upmanyu_efficient_2009, jain_image_2016, akramullah_video_2014}. Although it may produce results which do not correlate with human visual perception~\cite{huynh-thu_accuracy_2012, ahmed_benchmark_2016}, it is a valid indicator of image quality when media containing the same visual content is compared~\cite{huynh-thu_accuracy_2012}.
	PSNR is defined by
	\begin{align}
        \mathrm{PSNR} = 10\log_{10}{\left( \frac{L^2}{\mathrm{MSE}} \right)}
	\end{align}
	where $L$ is the maximum pixel intensity value of an image.
	Despite the known limitations of PSNR, since we are going to compare the effect of each encryption scheme on recovered image quality, given a fixed library of images, it is a valid measure of image quality for the study. A higher PSNR indicates higher image quality preservation.
	\item [Structural Similarity Index (SSIM).]
	The SSIM for two random variables $X$ and $Y$ is defined in~\cite{ahmed_benchmark_2016, akramullah_video_2014} as
	\begin{align}
        \mathrm{SSIM}(X,Y) = \frac{(2\mu_X\mu_Y+c_1)(2\sigma_{XY}+c_2)}{(\mu_X^2+\mu_Y^2+c_1)(\mu_X^2+\mu_Y^2+c_2)}
	\end{align}
	where
	\begin{itemize}
		\item $\mu_X, \mu_Y$ are the averages of $X$ and $Y$, respectively;
		\item $\sigma_X, \sigma_Y$ are the variances of $X$ and $Y$, respectively;
		\item $\sigma_{XY}$ is the covariance of $X$ and $Y$;
		\item $c_1 = (k_1L)^2, c_2 = (k_2L)^2$ are two variables used to stabilize the measure when $\mu_X^2+\mu_Y^2$ is close to zero~\cite{akramullah_video_2014};
		\item $L$ is the the maximum pixel intensity value of an image;
		\item $k_1 = 0.01, k_2 = 0.03$ by default, given in~\cite{ahmed_benchmark_2016}.
	\end{itemize}
	The SSIM is applied to the luminance value of two images to gauge structural similarity between neighboring pixels.
	For the study, we computed $\mathrm{SSIM}(\mathrm{PDT}, \mathrm{CDT})$ for every image operation, under each homomorphic cryptosystem. Higher values of SSIM indicate higher structural similarity, and an SSIM of $1$ indicates that the two images are identical~\cite{ahmed_benchmark_2016}.
\end{description}

Computing for MSE, PSNR, and SSIM was done using the corresponding built-in functions from the scikit-image Python library \cite{scikit-image}.

\subsection{Facial Recognition Tests}
%% TODO: Brian, can you fill this part up? Yes
The method for secure facial recognition using eigenfaces by Erkin, et al. \cite{hutchison_privacy-preserving_2009-2} was implemented for this study.
%Training data will be secured from The Database of Faces (\url{https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html}) maintained by AT&T Laboratories Cambridge.
Training and test data were secured from the \texttt{faces94} dataset (\url{https://cswww.essex.ac.uk/mv/allfaces/faces94.html}) maintained by the University of Essex. 

% Haar cascades will be implemented using homomorphic operations for facial detection.

% Each cryptosystem will be tested on accuracy (compared to unencrypted facial detection and recognition) and processing speed.

The facial recognition tests were done using ten-fold cross-validation for each cryptosystem, where the number of principal components used by the algorithm is fixed at $K=5$. 

Prior to splitting the dataset, the images within each set are shuffled. Since there are twenty (20) images per set, two images are taken at a time for each round of cross-validation. The first round would take the first two images from each set as part of the test set, and the rest of the images will be part of the training set. Then, the succeeding round would take the next two images from each set as part of the test set, and so on until ten rounds have been done. After every round of cross-validation, the accuracy score, confusion matrix, and total processing time were obtained. 

\section{Summary}
In summary, the study consists of:
\begin{itemize}
	\item Creating a wrapper library that acts as a unified interface which implements the Paillier, DGK, Dasgupta--Pal, and BGV homomorphic cryptosystems.
	\item An implementation of image processing operations (intensity transformations, facial recognition) under the above cryptosystems.
	\item Conducting tests for image quality, processing time, using standard test images from~\cite{gonzalez_image_nodate}.
\end{itemize}

%% insert flowchart/diagrams here
