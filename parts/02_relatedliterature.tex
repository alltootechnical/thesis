\chapter{REVIEW OF RELATED LITERATURE}

\section{An Introduction to Cryptography and Cryptosystems}
% [include mention of metrics by which they are compared]

In cryptography, a cryptosystem consists of an encryption function $\mathcal{E}$ and a decryption function $\mathcal{D}$, along with the plaintext space $\mathcal{P}$, ciphertext space $\mathcal{C}$ and the key space $\mathcal{K}$~\cite{tilborg_encyclopedia_2005}. A \textit{plaintext} is text that can be easily understood by everybody. On the other hand, a \textit{ciphertext} is a result from encrypting the plaintext using an encryption key. The plaintext space consists of all the possible plaintexts.

There are two kinds of cryptosystems, namely: \textit{symmetric} and \textit{asymmetric}. In symmetric encryption, the key is used for both encryption and decryption. On the other hand, asymmetric cryptosystems use separate keys for encryption and decryption. The encryption key (also called the \textit{public key}) is shared to everybody, while the decryption key (also called the \textit{private key}) is kept secret. Because of this, there is no need to agree upon some secure key sharing protocols. Usually, the security of asymmetric cryptosystems relies on the intractability of certain computational problems, like the RSA depends on the difficulty of integer factorization, while ElGamal depends on the difficulty of the discrete logarithmic problem.

A cryptosystem is said to be homomorphic if its encryption function is homomorphic, that is, if it satisfies the relation
\begin{equation}
    \mathcal{E}\left(p_1 \otimes p_2\right) = \mathcal{E}\left(p_1\right) \oplus \mathcal{E}\left(p_2\right)
\end{equation}
where $\otimes$ and $\oplus$ are operations in $\mathcal{P}$ and $\mathcal{C}$ respectively \cite{fontaine_survey_2007}.


\section{Common Image Operations}
% skim chapters 3-4 of the book Digital Image Processing

% we may refer to the classification in the CryptoImg paper

In image processing, the typical image operations being done are intensity transformations which maps intensity values to another, and the use of spatial filters to do operations such as edge detection and image blurring. 

\subsection{Intensity Transformation}
Intensity transformations are typically point operations, where a certain operation is applied to each single pixel of the image. Usually, there is a function $T$ that maps a pixel value $r$ into a new value $r^\prime$, thus this transformation satisfies the relation $r^\prime = T\left(r\right)$. Examples of intensity transformations are image negation, log transformation, and power-law transformation.

Image negation is an example of an intensity transformation, where the resulting image would be similar to a photographic negative~\cite{gonzalez_digital_2008}. In this case, suppose the intensity levels of an image are within the range $\left[0, L-1\right]$, then image negation can be expressed by
\begin{equation}
    T\left(r\right) = L-1-r
\end{equation}

The log transformation is used to enhance dark pixels or increase the dark details of an image by mapping low intensity values to a wider range of values~\cite{gonzalez_digital_2008}. This has the general form
\begin{equation}
    T\left(r\right) = c \log\left(1 + r\right)
\end{equation}
where $c$ is a constant and $r \ge 0$.

The power-law transformation is a family of transformations that have the form
\begin{equation}
    T\left(r\right) = c r^{\gamma}
\end{equation}
where $c>0$ and $\gamma > 0$. This is especially useful since many output devices such as printers and display devices follow the power law, and so correcting the power-law response on these devices in a process called \textit{gamma correction} ensures reproducibility and accuracy of images being displayed~\cite{gonzalez_digital_2008}.

\subsection{Edge Detection and Spatial Filters}
Edge detection is used to find and determine the boundaries in an image, commonly used in applications such as image segmentation and feature extraction. This works by detecting so-called \textit{edges}, areas that have abrupt changes in intensity. 
Edge detection is usually done by using gradient operators that detect such abrupt changes. These operators are commonly known as \textit{spatial filter}, which are usually of $3 \times 3$ size. A common example of spatial filters is the Sobel operator, with two matrices (also called as kernels) $g_x$ and $g_y$ representing the horizontal and vertical components respectively.
\begin{equation}
    g_x = 
    \begin{bmatrix}
        -1 & 0 & 1 \\
        -2 & 0 & 2 \\
        -1 & 0 & 1
    \end{bmatrix}
    \qquad\text{and}\qquad
    g_y = 
    \begin{bmatrix}
        1 & 2 & 1 \\
        0 & 0 & 0 \\
        -1 & -2 & -1
    \end{bmatrix}
\end{equation}

To get the resulting image $I^\prime$, a convolution is performed between the original image $I$ of size $M \times N$ and the kernel $k$ of size $m \times n$. Now suppose that the pixel value of an image at point $\left(i,j\right)$ is $r_{i,j}$. Then, a transformation using spatial filters can be described as follows:
\begin{align}
    T\left(r_{i,j}\right) &= \left[k * I\right]\left(\left\lfloor\frac{m}{2}\right\rfloor, \left\lfloor\frac{n}{2}\right\rfloor \right) \\
                         &= \sum_{u=1}^{m} \sum_{v=1}^{n} \left[k_{i,j} r_{i+u, j+v} \right]
\end{align}

Spatial filters are not only used for edge detection, but there are filters that do image blurring (such as Gaussian blur and box blur) and image sharpening.
% Should I put a table of other kernels too?


\section{Related Work and Previous Implementations}
There has been work done regarding the implementation of 
CryptoImg

example of homomorphic encryption / image manipulation past work

minor limitation: improvement on previous work, but not a direct comparison

major limitation: does not discuss security: are modified images also secure?

HElib

\section{Summary}


